{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Introduction\n",
    "\n",
    "With the surge of digital device and smart phones, billions of photos are collected everyday. For people who cares about the beauty or the feeling of photos, they hope to be instructed when they are taking or modifying photos to enhance aesthetic values. Also, people love to share photos and watch others' photos in social networks (Facebook, Instagram, snapchat, etc) they hope to share and watch the high-quality photos and got mediocre photos filtered out. Therefore, a trained 'aesthetic evaluator' will give them a pre-judgement about the 'beauty' of the photos, help them create, select best photos.\n",
    "\n",
    "Traditionally, deciding whether a natural image is beautiful always involves rational justification. According to our observation, appealing images usually share some common features such as regular compositions, gorgeous colors, an outstanding theme, or even some hidden features that human beings don’t realize.\n",
    "\n",
    "To build a brief view about aesthetics, there are three examples photos about the mountain. Although different people may have vary criteria and subjective aesthetic standard, the left two photos have higher aesthetic values than the right one undoubtedly.\n",
    "<img src=\"https://www.dropbox.com/s/ygrq2ehg9vc29m9/3img.png?raw=1\">\n",
    "\n",
    "\n",
    "How to find methods which can help us separates brilliant imags from mediocre images which have lower aesthetic values? In our project, we would explore different methods to solve this challenging question by establishing the aesthetic criteria from machine view and build an aesthetic classifier based on supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project content\n",
    "\n",
    "In this project, We will collect image dataset first, and then implement 3 feature extraction approaches, color histogram, convolutional neural network(CNN) with triple loss function and VGG pretrained network. All these featurets would be test on SVM classfier and compared with each other in the end.\n",
    "\n",
    "We will cover the following topics in this project:\n",
    "\n",
    "- [Data preparation](#Data-preparation)\n",
    "- [Image Color histogram](#Color-histogram)\n",
    "- [CNN with Triplet loss function](#CNN-with-Triplet-loss-function)\n",
    "- [VGG16 pretrained network](#Feature-Extraction-using-VGG16-pretrained-network)\n",
    "- [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mimetypes, httplib, time, sys, os\n",
    "import unittest\n",
    "import urllib2\n",
    "import cv2\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "One of the key factors contributing to our understanding of aesthetics of photographs is the dataset\n",
    "selection. The image quality and the rating system should be able to reflect the aesthetic value of\n",
    "a photo based on collective expertise.\n",
    "\n",
    "According to the criteria above, we chose the photos in Photo.net to train and test the algorithm. Photo.net is a great online photo sharing community with over 400,000 active photographers and they’re constantly doing peer-rating for each other’s works. \n",
    "\n",
    "To fetch the image data from photo.net, we have parsed the html page of photo.net, collected photos ids and scores information and downloaded image by id. In addition, the size of images in photo.net are different, we have croped and scaled images to have same size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse photo.net html page\n",
    "\n",
    "In photo.net http://photo.net/gallery/photocritique/filter, each finding photo request can match as many as 3000 photos and display 12 photos on each page. Therefore, we used loops to send different requests and collected image ids and scores on each page.\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/1nug4v1ftmftatb/photonet.png?raw=1\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different image ids obtained:  36692\n"
     ]
    }
   ],
   "source": [
    "def getPage(url):\n",
    "    \n",
    "    #Browser Information\n",
    "    user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "\n",
    "    request = urllib2.Request(url,headers = headers)\n",
    "\n",
    "    #Read response and open the url\n",
    "    response = urllib2.urlopen(request)\n",
    "\n",
    "    #Get web page HTML code and decode it\n",
    "    pageCode = response.read().decode('utf-8')\n",
    "\n",
    "    return pageCode\n",
    "\n",
    "def parse_page(html,ids,rates):\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    photos = soup.find_all(\"div\", attrs = {'class':'trp_photo'})\n",
    "    for photo in photos:\n",
    "        id = photo.find('a')['href'].split('=')[1]\n",
    "        rate = str(photo.find('div',attrs={'class':'trp-details'}))\n",
    "        l = rate.find(\"<strong>Rating:</strong>\")\n",
    "        r = rate.find(\"<br>\",l)\n",
    "        rate = rate[l:r].split(' ')[-1]\n",
    "        if(len(rate)<2):\n",
    "            continue\n",
    "        if id in ids:\n",
    "            continue\n",
    "        ids.append(id)\n",
    "        rates.append(float(rate))\n",
    "    return (ids,rates)\n",
    "    pass\n",
    "\n",
    "ids = []\n",
    "rates = []\n",
    "for page_index in range(0,3000,12):\n",
    "    for category in ['Travel','Landscape']:\n",
    "        for period in ['90','365','365-1','365-2','365-3','365-4','365-5','5000']:\n",
    "            url = \"http://photo.net/gallery/photocritique/filter?period=\"+ period \n",
    "            url += \"&rank_by=avg&category=\" + category + \"&start_index=\" + str(page_index) \n",
    "            url += \"&store_prefs_p=1&shown_tab=1&page=Next\"\n",
    "            html = getPage(url)\n",
    "            [ids,rates] = parse_page(html,ids,rates)\n",
    "print \"number of different image ids obtained: \",len(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After crawling the images, we visualize the score distribution to have a brief understanding of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEZCAYAAABWwhjiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYFOW1+PHvYRUUETdAcBcQdXRExQ3iEEWFxCWJ4i7g\nFqNR8+NqIi4BTTQ392Yxi5jEBUVFgt64o4DKaNxAUcMOgwiyyAgCwyowcH5/vNVM0fQ2PV1dVc35\nPE8/011VXXW6uqdPv0u9r6gqxhhjTD4ahR2AMcaY+LIkYowxJm+WRIwxxuTNkogxxpi8WRIxxhiT\nN0sixhhj8mZJxDSIiBwoIltFpJH3eIyIXFGgffcQkZm+x1+IyHcLsW9vf9NE5DuF2l89jjtcRFaI\nyIcp1l0qIq8XO6akGPqLyL+LcJztPjsmnuzNizDvS/Q9EVklIstF5N8iclzYcaWw7WIjVe2rqk9m\ne4L35XFIxp2qvquqXQsRoPfFfW/S/o9S1XcKsf96xNEDOB3YT1VPSl6vqiNV9exixpRGsS4gy+s4\nInKaiCwsdDA5HnuIiIwI49hR1CTsAExqItIKeBn4MfAs0AzoCWws8HEaqerWQu4zRxm/PESksapu\nKVYwRXQQMF9Vvw07kJgTipfoTCaqarcI3oDjgBVZtrkWmAGsBqYB5d7yw4EJwEpgKnCO7znDgWHA\nq8Aa4Lu4BPU7YAHwlbe+eZpjNvK2XQbMBW4AtgCNvPUTgKu8+4cClcAq4GvgGW/528BWYK0X+4XA\nacBC4OdeDE8klvmO/QVwOzAd+AZ4FGjmresP/Dsp1q3AId552gR86x3vRd/+vuvdbwY8ACwGFgF/\nBJp66xKxDQKqvW0GZHhf2gMvejHOAa7xll8FbAA2e3EMSfHc7V6H9xp+4u2nBrjXe03veed1FNDE\nt/3PgSXea7g6cQ68dX29c7c68XrSxN8feBf4i3eMGb7zdAHwcdL2g4Dn0+xrAnA/MNGL/3lgD2/d\ngV58V+I+e18Dd/iem/I9AVoC64Fa3Gd4NdAu03uYIq4hwD+9z9lq3P9Jt6T38Dkvps+Bm7zlZ+F+\nyG30jv1p2N8VYd9CD8Buad4YaIX7on4cODvxj+dbf6H3RdDNe3wIsD+udFkF/MK738v7J+nkbTcc\nl1xO8h439/7ZXgBaA7vivgDvSxPX9d6Xyn7AHsBbpE8iI4HB3v1mwCm+/WwFDvY9Pg335Xq/90XR\n3Fv2pW+bL4ApvmO/C9zrresPvJMU6xbqvkCHJ7ZN2l/iy/Fe4H1gL+/2HnBPUmxDgMZAH2Ad0DrN\nOXoH9wXcFDjG+yKqSBdn0nO3W++dp+e996UrLhGOx30Bt8IlhSu8bc/GJZDDgV2AJ5POwZLEe+C9\n1+UZYtgM3Oy93n64ZLKH9z4uB7r4tv8EOD/NvibgPqddgRa4L+YnvXWJJPJ3b79He6+vS47vyZdJ\nx0q7fYq4huAS0Vm4Us39wAfeOgE+Bu70Xv9BuB9MvX3PHRH2d0RUbqEHYLcMbw50AR4DvsT9kn4R\n2Mdb9zrer6Ok5/QAliQtGwn80rs/HHg8af1atv9CPxmYlyamN4HrfI97kz6JPAH8DeiQYj/bfiF7\nj0/zvkCaJi1LTiLX+h73Aaq8+6mSiP9XeLYkMhc4y7fuzMQ58OJYl3iN3rJqoHuK19UR9wXc0rfs\nfuCxdHEmPT9VEjnJ9/hj4Dbf498Bf/DuP4ov+eNKgv5zMB9XKmuV5XPXH1iUtGwicJl3fxjwK+/+\nkbgSV7pf/BOA+32Pu+J+xQsuiWwB2icdp1+O70lyEkm1/Rdp4hoCjEuKa513/0RclaN/+9uBR33P\ntSTi3axhPcJUdbaqXqWqBwBH4X6BP+Ct3h9XzE62H+6Xn98CoIPv8bb1IrIPrnpgstdjaAXwGu6X\nXCrJ+1+Q4SXchqv+miQiU0VkYIZtAZap6uYs2yxKOvZ+WbbP1X64ZJ1u39/o9m1H64Hd0uxnhaqu\nT9pXhxTb5upr3/0NuATmf5yII/m9Sf4c/Aj4HrBARCaIyA4N+z6Lkx77z8cTwKXe/cuB0Vnet+TP\nS1Ngb98y/+vxn9ds70myVNu3z7D90qTj7uL1FDsA6JD4fxCRlcBgYN8M+9ppWRKJCVWdg6vaOspb\ntBD3SzPZElyC8TuA7b8U1Hd/Oe4f6EhV3dO77aGqrdOE8lXS/g/MEPPXqnqdqnbAVYMNy9IjSzOs\nS0g+9hLv/jpcMgRARNrVc99L2P61+PddH0uAPUVkV9+y5PMflK9wJSH/cbe9blWdrKrnA/vgSrWj\nM+wrOekdgHc+VHUisElEeuKSSbbeeMnv2Sbc5y6bTO9JqvdzcYbt62MhrsST+H9oo6qtVfWcDMfe\naVkSiSgR6SIig0Skg/d4f+AS4ANvk0eAW0Wkm7f+UG+bicB6Efm5iDQRkQrg+8AzqY6jrnz+MPCA\nVypBRDqIyJlpQhsN3Oxt0wbX9pLuNVyQiB9Xp77Vu4H7FZixi28aN3rH3hO4A9ewDPAf4EgROVpE\nmuOqHPz/7NVZjvcMcJeI7C0iewN3k/3LcQequghXL/8bEWkuIkfjGrjrva88jAYGisjhItISuCux\nQkSaeteg7K6u19saXFVSOm1F5CbvM3Qhrp1ljG/9k8BfgU2q+n6WuC73xXQP8Kz3uQNXrZVOpvek\nGthLRHb3bT8qw/a5SMQyCVjj/Q/tIiKNReRIETned+yDRCRT7DsNSyLRtQZXNztRRNbgvpimALcC\nqOpzwH3ASBFZjWt83dOrVjgH1xNnOe4f/QpVrfL2m+pX1C9w9ckfisgqYBzQOU1cDwNjcV/aHwP/\nl7Tev/8TvPhX4xrub1bV+d66ocAIr7rggsynYrt9j/Tim4vrQHAfgPf67sW12cwBki+WexSXZFaI\nyL9SxPpr7/VM8b22+7LEks4lwMG4X8H/B9ytqhOyvbgcj5P2uKr6OvBnXDvEHOp+cCS6hV8BfOG9\nx9dRVyWVyodAJ9xn6FfAj1R1pW/9k7hScS5f0k/iqsCW4BrQb8nwenJ6T1R1Ni7JzPPe03aZtheR\n/UVktYj4S2rJ1Nv3VtwPr3Jcu9nXuM99ImE9i0s434jIxzm8/pImdT8IAti5+0X4Du6D0wR4TlXv\n8X7B/hNX3JyPa0ir8Z4zGNcVsha4RVXHecu74apzdgHGqOrPAgvcmBIgIofjuq421wJfCyQiu+B+\nkXdT1VRtc4ntJuB6Yz1WyOOb6Ai0JKKqG4FeqnosLqv3EZHuuJ4Ob6hqF1wX0cEAInIErjthV1zP\nm2G+IuNDwNWq2hnoLCJnBRm7MXEkIueLSDPvh9pvgZcKnUA8NwAfZUogZucQeHWWr5dKc1xpRIHz\ncMVbvL/ne/fPBUapaq1X7VEFdPeKqq1U9SNvuxG+5xhj6vwYV/1ShetqfEOhDyAiXwA3Af+Vw+bW\nCF3iAh/2xOsyNxnXk+hBVf1IRNqqajWAqi4VkUTXuQ7U1eOC623RAVe15e/auYiGdZk0piSpap8i\nHOPgemxbsAEzTTQVoySy1avO6ogrVRxJPRoLjTHGRFfRBmBU1dUiUokbmqE6URrxqqoSF1MtZvs+\n5R29ZemW70BELCEZY0weVLXe3ZYDLYl4/bVbe/db4IbImAm8BAzwNuuPu/AJb/nFXsPgwcBhwCRV\nXQrUiEh3r6H9St9zdhD2MAC53IYMGRJ6DKUQo8VpcUb9Foc4hwwZkvf3fNAlkfbAE167SCPgn6o6\nRtxkPKNF5Crc0AT9AFR1hoiMxg3wtxm4QVUTJYsb2b6Lb6gT9xhjjAk4iajqVKBbiuUrgDPSPOc3\nwG9SLJ8MlBU6RmOMMfmzK9ZDUlFREXYIWcUhRrA4C83iLKw4xNmQGAO9Yj0MIqKl9pqMMSZoIoJG\nrWHdGGNMabMkYowxJm+WRIwxxuTNkogxxpi8WRIxxhiTN0sixhhj8mZJxBhjTN4siRhjjMmbJRFj\nimDWLHjjjbCjMKbwLIkYUwSvvQa//GXYURhTeJZEjCmClSth0iRYtSrsSIwpLEsixhTBqlWwZQtM\nmBB2JMYUliURY4pg5Uo4+mgYNy7sSIwpLEsixhTBypVw0UWWREzpsSRiTBGsWgU9e8L69fD552FH\nY0zhWBIxpghWroQ2baB3bxg/PuxojCkcSyLGFEEiiZx5plVpmdJiMxsaUwQtW8Ly5bB6NXTtCsuW\nQZMmYUdlTB2b2dCYiNq4EWproUULaNcODjwQPvoo7KiMKQxLIsYELFGVJd5vvN69rUrLlA5LIsYE\nLJFEEqxdxJQSSyLGBGzVqu2TSI8eMGUK1NSEF5MxhWJJxJiArVwJe+xR97hFCzjlFBsCxZQGSyLG\nBCy5OgusXcSUDksixgQsuToLrF3ElA5LIsYELLk6C6CsDNautSFQTPwFmkREpKOIvCUi00Vkqojc\n5C0fIiKLROQT73a27zmDRaRKRGaKyJm+5d1EZIqIzBGRB4KM25hCSlWdJeJKIzYEiom7oEsitcAg\nVT0SOBn4qYgc7q37g6p2826vA4hIV6Af0BXoAwwTSfSu5yHgalXtDHQWkbMCjt2YgkhVnQU2jpYp\nDYEmEVVdqqqfeffXAjOBDt7qVJfXnweMUtVaVZ0PVAHdRaQd0EpVE9f5jgDODzJ2YwolVXUWwBln\nwFtvuavZjYmrorWJiMhBQDkw0Vv0UxH5TEQeEZHW3rIOwELf0xZ7yzoAi3zLF1GXjIyJtFTVWQDt\n28MBB9gQKCbeipJERGQ34DngFq9EMgw4RFXLgaXA74sRhzFhSFedBdZLy8Rf4OOIikgTXAJ5UlVf\nBFDVZb5NHgZe9u4vBvb3revoLUu3PKWhQ4duu19RUUFFRUXe8RvTUOmqs8C1i9x7LwwZUtyYjKms\nrKSysrLB+wl8KHgRGQEsV9VBvmXtVHWpd///ASeo6qUicgTwNHAirrpqPNBJVVVEPgRuBj4CXgX+\nnGiQTzqeDQVvIqV1a1iwIHUi2bAB9t0XFi1y2xkTlnyHgg+0JCIipwKXAVNF5FNAgTuAS0WkHNgK\nzAd+DKCqM0RkNDAD2Azc4MsINwKPA7sAY1IlEGOiZssWWLcOdt899foWLeDkk90QKOdbVxETQzYp\nlTEBWrECDj3UVWml87vfwbx5MGxY8eIyJplNSmVMBKXrmeVn14uYOLMkYkyAckkiZWWwZo0rjRgT\nN5ZEjAnQqlXpe2YlNGpkpRETX5ZEjAlQLiURsOtFTHxZEjEmQLkmkd693RAoU6cGH5MxhWRJxJgA\n5VKdBdCuHTz4IJx+OrzxRvBxGVMolkSMCVCuJRGASy+FZ5+Fyy6Dxx8PNCxjCibwYU+M2ZmtXOkG\nWczVaadBZSX07QtffAFDh7q5R4yJKiuJGBOgXKuz/Lp2hQ8/hDFjYMAA2LQpt+dt2gQ1NfUO0ZgG\nsSRiTIDqU53l17atK5GsWgV9+ri/qdTUwKhRcPHFsM8+rgRjTDFZEjEmQPkmEYBdd4V//QuOPBJ6\n9IAvv3TLFy+Ghx6Cs86C/feHp55yDfJTp8K0abB8eeHiNyYbaxMxJkD5VGf5NW4Mf/oTPPAAnHIK\n7LcfzJ0L3/seXHstPPcctGpVt32vXjB2rGucN6YYbABGYwK0zz4wfbob7r2h3nkHNm+G73wHmjZN\nvc0//gFvvw1PP93w45mdS74DMFoSMSYgqtCsGaxfn/5Lv9AWLYLycqiudqUYY3Jlo/gaEzFr10Lz\n5sVLIAAdO0KHDjBxYvGOaXZulkSMCUhD20Py1bev6x5sTDFYEjEmIA3pmdUQlkRMMVkSMSYgYSWR\nk0+G+fNhyZLiH9vsfCyJGBOQsKqzmjRxQ8u/9lrxj212PpZEjAlIWCURsCotUzyWRIwJSJhJ5Oyz\n4c03cx93y5h8WRIxJiBhVWeBu7ixc2d4771wjm92HpZEjAlImCURcEOjWJWWCZolEWMCEnYS6dsX\nXn01vOObnYMlEWMCEmZ1FsBxx7kRfb/4IrwYTOmzJGJMQMIuiTRq5OYisa6+JkiWRIwJSNhJBKyr\nrwmeJRFjAhJ2dRa4iw7feQc2bAg3DlO6LIkYE5AolETatHFDw1dWhhuHKV2BJhER6Sgib4nIdBGZ\nKiI3e8vbiMg4EZktImNFpLXvOYNFpEpEZorImb7l3URkiojMEZEHgozbmIbauBFqa6Fly7AjsSot\nE6ygSyK1wCBVPRI4GbhRRA4HbgfeUNUuwFvAYAAROQLoB3QF+gDDRCQxScpDwNWq2hnoLCJnBRy7\nMXlbudJVZUm9p/gpvEQSsbnaTBACTSKqulRVP/PurwVmAh2B84AnvM2eAM737p8LjFLVWlWdD1QB\n3UWkHdBKVT/ythvhe44xkbNqVfhVWQllZW74kzlzwo7ElKKitYmIyEFAOfAh0FZVq8ElGiAxA3UH\nYKHvaYu9ZR2ARb7li7xlxkRSFNpDEkTswkMTnCbFOIiI7AY8B9yiqmtFJLlgXdCC9tChQ7fdr6io\noKKiopC7NyarRHVWVPTtC3/5CwwaFHYkJioqKyupLECPC9GAK0pFpAnwCvCaqv7JWzYTqFDVaq+q\naoKqdhWR2wFV1d96270ODAEWJLbxll8MnKaqP0lxPA36NRmTzciR8PLL8MwzYUfirF0L7du7iapa\ntQo7GhNFIoKq1rsVrxjVWY8BMxIJxPMSMMC73x940bf8YhFpJiIHA4cBk7wqrxoR6e41tF/pe44x\nkROl6iyA3XZzMx6++WbYkZhSE3QX31OBy4DvisinIvKJiJwN/BboLSKzgdOB/wZQ1RnAaGAGMAa4\nwVesuBF4FJgDVKnq60HGbkxDRK06C6xdxAQj8OqsYrPqLBMFt94KbdvCbbeFHUmdOXOgVy9YtCga\nXY9NtES5OsuYnU7UqrMAOnWC3XeHDz4IOxJTSiyJGBOAKFZniUD//jB8eNiRmFJiScSYAETpYkO/\nK6+E//s/WLcu7EhMqbAkYkwAolidBbDffq6X1r/+FXYkplRYEjEmAFFNIgADB8Jjj4UdhSkVlkRM\nrH37bTQbiqPYJpJwzjkwbRrMmxd2JKYUWBIxsTZmDHznO9FKJFu2uCvEW7fOvm0YmjeHSy+FJ57I\nvq0x2VgSMbE2c6abdOmii2D58rCjcWpqXFfaRhH+7xo4EB5/HLZuDTsSE3cR/pgbk92sWXDjjXDJ\nJXDZZa4UELYoV2UllJfDnnvCW2+FHYmJO0siJtZmzYLDD4f77nPtI/fdF3ZE0e3em+yqq+yaEdNw\nlkRMbKnWJZEmTWDUKPjb32D8+HDjinLPLL9LL3Vjaa1aFXYkJs4siZjYWrzYjU6bqDpq3x6eftpd\nULdoUebnBikO1VkAe+0FvXu75GtMviyJmNhKlEL8evWCm292De2bN4cTV1yqs8CqtEzDWRIxsZUq\niQD84hfuS/z224sfE8SnOgvgzDNdqW369LAjMXFlScTEVrok0qgRjBjhhvYIY3iPuFRnATRu7Kr/\nrDRi8mVJxMTWzJnQtWvqdXvuCc8+C9dfD1VVxY0rTtVZ4K4Zeeqp8Kr/TLxZEjGxla4kknD88XDP\nPXDBBbBxY/7HqamBBx7Iffs4VWcBdO4Mhx0Gr70WdiQmjiyJmFhavdr94u/YMfN211/vvtBffDH/\nYz31FAwenPuFjHGqzkqwQRlNviyJmFiaPRu6dMk+tIgIXHttw+r8hw93VT1z5+a2fdyqswD69YPK\nSvj667AjMXFjScTEUraqLL8f/hAmToSFC+t/nKlToboa+vZ193MRt+osgFat4PzzXanLmPrIKYmI\nyKm5LDOmWDI1qidr0cJdNzJiRP2PM3y46710zDEwZUpuz4ljdRbUVWmphh2JiZNcSyJ/yXGZMUVR\nn5IIuC/I4cPr9wW5ebO7An7AACgry60kohrP6ixwQ+pv2AAffxx2JCZOmmRaKSInA6cA+4jIIN+q\n3YHGQQZmTCb1TSInnAC77AL//rf7sszFq6+6nkudOkFtLdxxR/bnrFsHzZq5W9yIuJGQn3vOnS9j\ncpGtJNIM2A2XbFr5bquBC4INzZjUNm92s/J16pT7c0TcEB/16YE0fLgrwYA71pIlLklkEteqrITT\nT4cJE8KOwsRJxpKIqr4NvC0ij6vqgiLFZExG8+ZBhw6uZFEfl1/uenStWeMakjOproa3365raG7S\nxJV8pk+H7t3TPy+Ojep+J53k2ptqaqI7M6OJllzbRJqLyD9EZJyIvJW4BRqZMWnMmpV7o7rfvvtC\nRQWMHp1926eecr2V/Mkml3aRuLaHJDRv7pLkv/8ddiQmLnJNIs8CnwJ3Abf5bsYUXX3bQ/xyuahO\ndfuqrIRckkjcq7PAjYRsVVomV7kmkVpVfUhVJ6nq5MQt0MiMSaMhSaRPH/j8c3exYjqTJ8P69dCz\n5/bLy8qyd/ONe3UWWBIx9ZNrEnlZRG4QkfYismfilu1JIvKoiFSLyBTfsiEiskhEPvFuZ/vWDRaR\nKhGZKSJn+pZ3E5EpIjJHROoxipEpRTNn5p9EmjbNPmrt8OGuW2/y1fCJkkimbsJxr84C1zNr7lxY\nsSLsSEwc5JpE+uOqr94HJnu3XHqTDwfOSrH8D6razbu9DiAiXYF+QFegDzBMRMTb/iHgalXtDHQW\nkVT7NDuBxJS4+bSJJAwc6C48rK3dcd2337qZ/vr333Fd+/awdatrdE+nFKqzmjWDk0+Gd94JOxIT\nBzklEVU9OMXtkBye9y6wMsUqSbHsPGCUqtaq6nygCuguIu2AVqr6kbfdCOD8XOI2pae62pUm9tor\n/3107QoHHghjx+647sUX4dhj3fpkInD00ZnbRUqhOgusSsvkLtdhT65MdWvAcX8qIp+JyCMikuhI\n2AHwj2602FvWAfDPmL3IW2Z2Qg1pD/FLd81IqgZ1v2yN66VQnQWWREzuMl4n4uO/fnUX4HTgE1yp\noL6GAfeqqorIr4HfA9fksZ+0hg4duu1+RUUFFRUVhdy9CVFD2kP8LroIbrsNli2DffZxyxYtgkmT\nMs+GWFYG77+ffn2plESOOw4WLNj+/JjSUllZSWVlZYP3k1MSUdWb/I9FZA9gVD4HVNVlvocPAy97\n9xcD+/vWdfSWpVuelj+JmNJSqJLI7rvDuee6sbF+9jO3bMQIuPBCaNky/fPKyuDvf0+/vhTaRMBd\nXNmjh7vg8gIbm6IkJf/Avueee/LaT75Dwa8DDs5xW8HXBuK1cST8EJjm3X8JuFhEmonIwcBhwCRV\nXQrUiEh3r6H9SqABUwyZOGtoo7qff9TadNeGJDvySJgxI/0EVaVSEgGr0jK5yakkIiIvA4mOjY1x\nPaiyXvcrIiOBCmAvEfkSGAL0EpFyYCswH/gxgKrOEJHRwAxgM3CD6rbOlDcCj+Oq0sYkenSZnU+h\nSiIAp50Ga9fCJ5+40WubNIETT8z8nFatoF071wW2S5cd15dKmwi4JGKzHZpsRHMYG1tETvM9rAUW\nqOqidNuHSUQ0l9dk4mfdOth7b/fF37hAY0j/6lewdKnr2tulC/z859mfc955cMUVqat5WrZ0swPu\ntlth4gvTli3ufM+c6RKnKW0igqqm6jmbUa5dfN8GZuFG8G0DbKrvgYxpqNmz3Wi6hUog4K4HGTXK\nNaZfcUVuz0nXzXfjRjfC8K67Fi6+MDVu7IbNL0DbqylhuXbx7QdMAi7EXRA4UUSsuc0UVSHbQxIO\nOMD1RDr1VHcxYS7SdfNNVGVJvX/LRZe1i5hscu3ieydwgqp+DSAi+wBvAM8FFZgxyQrZHuL35z/X\nr3RTVgZ33rnj8lLpmeXXqxcMGxZ2FCbKcu2d1SiRQDzf1OO5xhREUEnk8MPrN8FVp06wePGOE1SV\nUs+shLIyN4bW4oyd6s3OLNdE8LqIjBWRASIyAHgVGBNcWMbsqFAXGjZUkyauEX7GjO2Xl1LPrIRG\njVwvNqvSMulkTCIicpiInKqqtwF/B472bh8A/yhCfMYArqfQ3LluzvMoSDUsfClWZ4G1i5jMspVE\nHsDNp46q/ktVB6nqIOB5b50xRTF/PrRtG52eT6ka10uxOgssiZjMsiWRtqq6Qz8Ub9lBgURkTApB\ntYfkK1U331KszgI44gjX/rNgQWH29/nnhduXCV+2JJKpcN6ikIEYk0lU2kMS0pVESrE6S8TNTd/Q\n0sjChXDddS4p3X13QUIzEZAtiXwsItcmLxSRa3ATUxlTFFEribRv79pp/BNUlWp1FjSsSmvZMhg0\nCMrL3RXwr74Kn31W2PhMeLJdJ/Iz4HkRuYy6pHE80Az4QZCBGeM3axZcfnnYUdQRqSuNtG3rlpVq\ndRa4JHL//W6gylwvpqypgd//Hh58EC69FKZPd8OnfPstVFW5K/ybNw82bhO8jCURVa1W1VOAe3CD\nJc4H7lHVk73RdY0piiCuVm+o5CqtUq3OAtcrrrYW5s3Lvu369fC//+uup1m4ECZPhr/8pW78rV12\ngUMP3bGLtImnXOcTmQBY/wwTimXLXNXRvvuGHcn2ysrggw/qHpdydZZIXZXWoYem327cOLj2Wjjh\nBDfm1hFHpN6uvBz+8x83FbGJN7vq3EReoj0kamNSpSqJlGoSgcztImvWwPXXwzXXwCOPwHPPpU8g\nAMccY+0ipcKSiIm8qDWqJxx1lOs1lpigatWq0q3OgrokkjzTQmWlSwqbNrmk2rt39n2Vl1sSKRWW\nREzkRbE9BNwEVW3buusetmxxv8Zbtw47quAccogb8mXOHPd4/Xq45Ra47DI3iOVjj+X++o85xlVn\n2dQ/8WdJxEReVEsiUFelVVPjkkoh5zqJGn+7yPvvu9LE8uXu9X//+/Xb1777QosW8OWXwcRqiifX\noeCNCU3ULjT0SySRY48t7aqshF694K67XMnrwQfhhz/Mf1+JxvUDDyxcfKb4rCRiIm3DBliyBA4+\nOOxIUkskkVJvVE/43vfgwgvdl39DEghEu3F91iz40Y/glVfCjiT6LImYSKuqcnXxTZuGHUlqidF8\nd5Ykss8+8Mc/Fqa7dRQb17/5Bm6+GXr2hNWr3dX1JjNLIibSotqonpCYoGrx4p2jOquQEo3rUbB5\ns+sc0LWy0r8rAAAXXElEQVSrq6qbOROGDnUXSprMrE3ERFqU20PAlZC6dHENzTtDSaSQOnWCpUtd\np4SwerWpwpgx8F//5dpmJkyAI49061q0gGnTXNflZs3CiS8OrCRiImvsWPjb3+A73wk7kszKyuCd\ndyyJ1Ffjxqkn9yqWadPgrLPg1lvhD3+A11+vSyDg5q45+GA35pdJz5KIiZyNG90vw2uugZEj3T96\nlJWVuWo3SyL1F1aV1pYt0KMHnHOOS2J9+6YeEeH4461KKxtLIiZSZs2Ck05yA/199pnrUhp1ZWXu\nr7WJ1F9Yjetffgm77w433ZS508Zxx1kSycaSiIkEVTfmUs+ebgymf/0L9tor7Khyk0giVhKpv7BK\nInPmuJGJsznuOPj44+DjiTNrWDehW7HCzXhXVQVvv5154L4o2m8/l0AsidRfWZlrc6itdUOqFEuu\nSaS83MVnjevpWUnEhKK21l1bMX68+0ft2BEmToxfAgFXl37FFbl9KZnttWrl3vvZs4t73FyTyK67\nuuuUrHE9vUCTiIg8KiLVIjLFt6yNiIwTkdkiMlZEWvvWDRaRKhGZKSJn+pZ3E5EpIjJHRB4IMmZT\nOJMnw3nnufm5jzvOdels1w5atnQz2h18MPz0p64H1gMPuMmK4upPf8o8z4ZJL4wqrVyTCFi7SDZB\nl0SGA8l9a24H3lDVLsBbwGAAETkC6Ad0BfoAw0S29Zd4CLhaVTsDnUUk4v11jCrccIPr3TJkCPz9\n7+7q308/dZNM1da6odNnz3Y9Y8zOK4zG9fomEWsXSS/QWkhVfVdEkodXOw84zbv/BFCJSyznAqNU\ntRaYLyJVQHcRWQC0UtWPvOeMAM4HxgYZu2mY55939ch33gmNrNLUZHDMMW763GL59lv46is46KDc\ntj/uOHjyyUBDirUw/r33VdVqAG+e9sQoPB2Ahb7tFnvLOgCLfMsXectMRNXWuuTxm99YAjHZlZe7\nEmqx5hb5/HOXQHJtyC8vd/PBb9oUaFixFYXeWQX/6AwdOnTb/YqKCioqKgp9CJPBE0+4yZqifpGg\niYYOHWDrVjcESvv2wR+vPlVZsP2V66U0J3xlZSWVlZUN3k8YSaRaRNqqarWItAO+9pYvBvb3bdfR\nW5ZueVr+JGKKa8MGN3Dds89Gb050E00idY3rUUwiUNcuUkpJJPkH9j333JPXfopR2SDeLeElYIB3\nvz/wom/5xSLSTEQOBg4DJnlVXjUi0t1raL/S9xwTMQ8+6BrTTzop7EhMnBSzcT3fJGI9tFILuovv\nSOB9XI+qL0VkIPDfQG8RmQ2c7j1GVWcAo4EZwBjgBtVttaQ3Ao8Cc4AqVX09yLhNflatgv/5H7jv\nvrAjMXFTzAmq8kkiNoZWeqLFas0qEhHRUntNcXHnna7Xy2OPhR2JiZspU+Cii9zQ/0Fr29Y15O+3\nX+7PWb8e9t7b/VAq1SvXRQRVrXcltCURUxBffQVHHeX+OQ84IOxoTNxs2uQGsFy+3F2MGpRVq9wV\n8mvW1L/N7qijYMQI6NYtmNjClm8SsQ6YpiB+9SsYMMASiMlPs2Zucq9p04I9TlWVq8rKp9OHtYuk\nZknENNjcuTB6NNxxR9iRmDgrRuN6Ionkw9pFUrMkYhrs7rvhZz+Lz9DtJpqK0bieT6N6gg1/kpol\nEZOSKowbB998k3m7Tz+FykqXRIxpiPLy4AdibEgSsSvXU7MkYlKaNQvOP99dqXvSSXDPPTBpkruy\n2G/wYLjrLthtt3DiNKXjmGNcL63kz1ghNSSJtGzphoUPut0mbiyJmJRmzYIzznAj7t53n+vNMnCg\n6x55+eXw9NNu9sGqKrj22rCjNaWgTRvYc083tlUQVF0S6dQp/31Y4/qOLImYlGbNgsMPd/N+nH46\n/O53buygjz92U9g++yz07+8GWSzVfvOm+IKs0qqudp/nhsxAefzx1i6SzJKISWnWLNflMtmBB8KP\nfwwvvACrV0O/fsWPzZSuIBvXG1KVlWAlkR1ZEjEpzZ7tSiKZ2ACLptCCLIkUIolY4/qOLImYHajW\nVWcZU0xBXitSiCRijes7siRidlBd7Sbsses+TLEddBDU1GTvWp6PQiQRsHaRZJZEzA5yqcoyJgiN\nGtXNLVJohUoi1i6yPUsiZgdWlWXCFETj+pYtMG8eHHZYw/dlSWR7lkTMDtL1zDKmGIJoXF+wwF3j\n1KJFw/eVaFzfuLHh+yoFlkTMDqwkYsJUXu7aHLZsKdw+C1WVBa5x/dBDrXE9wZKI2YG1iZgwlZXB\nvvvC0UfDiy+63oINVcgkAlal5WdJxGxnwwZYssSNmWVMGJo3h7feclMt3303nHoqvPNOw/ZpSSQ4\nlkTMdqqqXD/4Jk3CjsTszETge99zo0TfcIMbYqdv3/zbSiyJBMeSiNmOVWWZKGnc2A34OWsW9OkD\nZ53lHs+bV7/9FDqJWON6HUsiZjvWM8tEUfPmcNNNdTMTdu/u5rHJxYYNsHSpG/etUKxxvY4lEbMd\n65lloqxVK/jlL+HXv4Zhw3J7zuefuza+QlfRWpWWY0nEbMeqs0wcXHSRm3lzxYrs2xa6KivBkohj\nScRskxh40aqzTNS1aePaSJ55Jvu2QSWRU06BN94o7PUscWRJxGyzeLGb5naPPcKOxJjsBgyAxx/P\nvl1QSaRbN2jfHkaPLvy+48SSiNnGqrJMnJxxBnz1VfbG7URjfKGJuOtY7rsv2Hnho86SiNnGqrJM\nnDRuDFdemb00ElRJBODMM914XC+8EMz+48CSSIm6+25Ytqx+z7GeWSZu+veHp56CzZtTr1+1Ctav\nh3btgjl+ojTy618XZniWOAotiYjIfBH5j4h8KiKTvGVtRGSciMwWkbEi0tq3/WARqRKRmSJyZlhx\nx8G0ae5D/eqr9XueVWeZuOnSxY2wMHZs6vVVVdCpU7BTOZ9zjqvOqu//W6kIsySyFahQ1WNVtbu3\n7HbgDVXtArwFDAYQkSOAfkBXoA8wTMRm+E7nkUdcv/g33qjf86w6y8TRwIHpq7SCrMpKEIE779x5\nSyNhJhFJcfzzgCe8+08A53v3zwVGqWqtqs4HqoDumB18+60r3j/yiEsiuX6o161z1V+FvKrXmGLo\n18991pcv33FdMZIIwI9+BKtX1/+HWykIM4koMF5EPhKRa7xlbVW1GkBVlwL7ess7AAt9z13sLTNJ\nnn8ejj0Wvvtd2HVXmD49t+fNmeOK/Y0bBxufMYXWurUbrDHVNSPFSiKNGrnSyK9+FfyxoibMJHKq\nqnYD+gI3ikhPXGLx2wkLhw3z8MNw7bXu/hln5P7LyKqyTJylq9IqVhIBdxX9kiUNH7Y+bkIb8FtV\nv/L+LhORF3DVU9Ui0lZVq0WkHfC1t/liYH/f0zt6y1IaOnTotvsVFRVUVFQUNviImjvXNaqfd557\n3Ls3DB8OP/tZ9udazywTZ716uerYKVPcZFbgqnITJexiaNIE7rjDlUbGjy/OMRuisrKSylxHscxA\nNISWIBFpCTRS1bUisiswDrgHOB1Yoaq/FZFfAG1U9XavYf1p4ERcNdZ4oJOmCF5EUi3eKQwe7Lo6\n/u537vE337gG9uXLoVmzzM+9+GLXy+Syy4KP05gg3HWX6877hz+4x199BcccA19/nfl5hbR5s0ta\no0bBSScV77iFICKoar07LIVVndUWeFdEPgU+BF5W1XHAb4HeIjIbl1D+G0BVZwCjgRnAGOCGnTZT\npLF5syvOX3113bK99nJF+YkTsz/fqrNM3A0YAE8/XXfNSDGrshKaNoVf/ML11NpZhJJEVPULVS33\nuveWqWoiWaxQ1TNUtYuqnqmqq3zP+Y2qHqaqXb2EY3xeeQUOOwy6dt1+eS7tIlu3un84SyImzg47\nzCWN115zj8NIIuDaZz77DD75pPjHDoNdsV4iHnmkrkHdr3fv7Elk4ULYc083V4MxcTZggGsHhPCS\nyC67wG237TylEUsiJWDhQvjwQ7jggh3XnXqqa2ysqUn/fGtUN6WiXz+YMME1soeVRMD9oHv//Z1j\n5kNLIiXgscdcw3jLljuu22UX18D39tvpn2/tIaZUtGoF554LI0eGm0RatoRBg9wIv6XOkkjMbdni\nkkiqqqyEbO0iNmaWKSUDBsCjj8IXX7h50MPyk5/Am2+6rvelzJJIzI0fD/vuC+Xl6bfJ1i5i1Vmm\nlFRUuCFI2rVzw7SHpVUruOqq3OeCjytLIjHnv0I9nfJy11d+0aLU6606y5SSRo3cEPHFusgwk+uv\nhxEj3Nh0pSqUiw2DtDNdbFhd7UoQCxbA7rtn3rZfPze+UP/+2y9fvdpN8blmjfvnM6YU1NS4H01H\nHhl2JG4Eie9/P/uPvbDF7WJDUwBPPAE//GH2BALp20Vmz3alEEsgppS0bh2NBAJw443w4IOlO0y8\nfXXElGr6a0NSSSSR5A+yVWUZE6wzzoANG+C998KOJBiWRGLq7bfdeFgnnpjb9occ4rodzpix/XJr\nVDcmWI0awQ03uNJIKbIkEkFbt6afMzohUQqpz/yOZ5yx4+ii1r3XmOD17w+vv+4GhSw11rAeMatX\nw9lnu0ETd9vNDUeSuO21l/vbpo3rNvj55+5xrp591rWjvPJK3bKjjnIzIWbqImyMabjrr4f99oNf\n/jLsSFLLt2HdkkiErFvnEshRR7mi75o1sGKFG9J9xYrt73fu7CbBqY9vvnHVWsuXu9FGt2xxieqb\nb1Jf7W6MKZypU93/9/z57v8vavJNIqFNSmW2t2GDG66hUyeXQBo1cj1MWrd2c4IUwl57uf1PnAg9\nergPc9u2lkCMKYayMjfS8AsvwIUXhh1N4VibSARs3Oi66rZr5y4eDLK7rb9dxHpmGVNcN94If/1r\n2FEUliWRkG3a5H6V7Lqra69o3DjY4/mvF7GeWcYU1w9+4MbSmjo17EgKx5JIiGpr66ajHTnSzdEc\ntMTQ8KtXW88sY4qtaVO47rrSGk/LkkhItmxx3f7WrHG9prLNgV4oLVrUDQ1v1VnGFN9117k52DPN\n8RMnlkRCsHWru8bjq6/g+eehefPiHj9RpWXVWcYUX/v2cNZZrvq6FFgX3yLbtAluusldOf76664t\npNgmT4bzz3e/hGpq6nfBojGm4d59F66+GmbOjM64dTYAYwx89BEcfzwsXgyvvhpOAgF3YeH69a4q\nyxKIMcV36qlu1tE33ww7koazJFIE69fDbbfBOefA7bfDyy/nNvJuUBo3htNPt6osY8IiUjrdfa06\nK2CVlXDNNdC9O/zpT7DPPmFH5Lz9Nnz7raubNcYU37p1cMABrnr5oIPCjsaGPdkmKkmkpgZ+/nMY\nM8Z15zvnnLAjMsZEza23wvTprrdW69bhxmJtIhHyyitu/CuAadMsgRhjUrv/fjcUyvHHu+u34shK\nIgVSXQ3//Cc8/bQb0PDhh6FXr6KHYYyJoZEj4ZZb4Pe/hyuvDCcGq87yFDOJrF3rrvN4+mn48ENX\n4rjsMncdRjGuPjfGlI7p090Yer16wQMPuN5bxWRJxBN0Etm8GcaOdYljzBjo2dMljnPPDa/LrjGm\nNKxeDVddBQsWuJEsitngvlMkERE5G3gA15bzqKr+NsU2DU4iW7bAwoVQVeUGS5s7t+7+F19At24u\ncVx4YXR6WxljSoMq/PGP8Nvfuqvazz67OMct+YZ1EWkE/BU4CzgSuEREGnylQ20tfPYZPPSQq4s8\n4ghXoujZ0zV6ffqpm3Nj4EDX5vHNN/Dee27O5IYkkMrKyoaGHrg4xAgWZ6FZnIVV3zhFYNAgeO45\nd1X70KFuqKQgNeRcxiaJAN2BKlVdoKqbgVHAefXdyfLlrvfUnXfCd7/rppe95BJ3NXmPHvDMM7By\npSuJTJgA//iH66r7gx+4SWUKNYFTHP4B4hAjWJyFZnEWVr5x9uzpriFp0iT4kSUaci7j1PzbAVjo\ne7wIl1h2sG6dm3/cXw2V+Ltmjbvw7+ST3VXkJ55Yv3nKjTGmWNq1g7vuCjuKzOKURHK2995uLvFO\nnVwf7OOOg4svdvf33z86A54ZY0zcxaZhXUROAoaq6tne49sBTW5cF5F4vCBjjImYku6dJSKNgdnA\n6cBXwCTgElWdGWpgxhizE4tNdZaqbhGRnwLjqOviawnEGGNCFJuSiDHGmOiJXROziDQXkYki8qmI\nTBWRIWm2+7OIVInIZyJSHsU4ReQ0EVklIp94t9D6YYhIIy+Gl9KsD/V8+uJIG2dUzqeIzBeR/3jv\n/aQ024R+PrPFGaHz2VpEnhWRmSIyXUROTLFN2P/vGWOMwrkUkc7ee/2J97dGRG5OsV39zqWqxu4G\ntPT+NgY+BLonre8DvOrdPxH4MKJxnga8FPb59GL5f8BTqeKJyvnMIc5InE9gHtAmw/pInM8c4ozK\n+XwcGOjdbwLsHrXzmUOMkTiXvngaAUuA/Rt6LmNXEgFQ1fXe3ea4Nyy5Tu48YIS37USgtYi0LV6E\nTg5xAoQ+Qa2IdAT6Ao+k2SQS5zOHOCEC5xMXQ6b/rUicT7LHmdgmNCKyO9BTVYcDqGqtqq5O2izU\n85ljjBCNz2bCGcDnqrowaXm9z2Usk4hXpfEpsBQYr6ofJW2SfGHiYm9ZUeUQJ8DJXrHxVRE5osgh\nJvwRuI3USQ4icj7JHidE43wqMF5EPhKRa1Osj8r5zBYnhH8+DwaWi8hwrxrmHyLSImmbsM9nLjFC\n+OfS7yLgmRTL630uY5lEVHWrqh4LdAROjMAbklIOcU4GDlDVcty4YC8UO0YR+R5Qraqf4X4pRenX\n0jY5xhn6+fScqqrdcKWmG0WkR0hxZJMtziiczyZAN+BBL9b1wO0hxJFJLjFG4VwCICJNgXOBZwux\nv1gmkQSvyDgBSB7ncjGwv+9xR29ZKNLFqaprE1Veqvoa0FREij0Iy6nAuSIyD/fLpJeIjEjaJgrn\nM2ucETmfqOpX3t9lwPPsODxPFM5n1jgjcj4XAQtV9WPv8XO4L2y/sM9n1hgjci4T+gCTvfc9Wb3P\nZeySiIjsLSKtvfstgN7ArKTNXgKu9LY5CVilqtVRi9Nf1ygi3XFdrlcUM05VvUNVD1DVQ4CLgbdU\nNXlutdDPZy5xRuF8ikhLEdnNu78rcCYwLWmz0M9nLnFG4Xx652WhiHT2Fp0OzEjaLNTzmUuMUTiX\nPpeQuioL8jiXsbnY0Kc98IS4oeEbAf9U1TEi8mPcMCj/8B73FZG5wDpgYBTjBC4QkZ8Am4ENuHrK\nSIjg+UwpguezLfC8uOF3mgBPq+q4CJ7PrHESjfMJcDPwtFcNMw8YGMHzmTFGInIuRaQlrlH9Ot+y\nBp1Lu9jQGGNM3mJXnWWMMSY6LIkYY4zJmyURY4wxebMkYowxJm+WRIwxxuTNkogxxpi8WRIxJk8i\ncqeITBM3nPonInJC2DEZU2xxvNjQmNB5V/P2BcpVtdYbwqJZA/bXWFW3FCxAY4rESiLG5Kc9sFxV\nawFUdYWqLhWRE0TkPW+01g9FZFdxE5Q9JiJTRGSyiFQAiEh/EXlRRN4E3vCW3Soik7znp5xwzZgo\nsZKIMfkZB/xSRGYBbwL/BD4ARgEXquon3thU3wK3AFtV9WgR6QKME5FO3n6OBcpUtUZEegOdVLW7\niAjwkoj0UNV3i/3ijMmVlUSMyYOqrsON1HodsAyXPH4MLFHVT7xt1npVVD1wszGiqrOB+UBisL7x\nqlrj3T8T6C0inwCfAF2ARLIxJpKsJGJMntQNPPcO8I6ITAVuzPGp/rlQ1iUt/42qPlygEI0JnJVE\njMmDiHQWkcN8i8pxw3+3F5HjvW12E5HGwL+ByxLPw83XMDvFbscCV3lDsyMi+4nIPgG+DGMazEoi\nxuRnN+Av3pwxtcBcXNXWcOCv3hwy63HDbg8DHhKRKbihwPur6mbX7FFHVceLyOHAB966NcDluOoy\nYyLJhoI3xhiTN6vOMsYYkzdLIsYYY/JmScQYY0zeLIkYY4zJmyURY4wxebMkYowxJm+WRIwxxuTN\nkogxxpi8/X8XwFfmvmKEWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107e0fa50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#score distribution visualization\n",
    "scores = rates\n",
    "rate = {}\n",
    "for score in scores:\n",
    "    score = int(score*10)\n",
    "    if score not in rate:\n",
    "        rate[score] = 0\n",
    "    rate[score] += 1\n",
    "sd = sorted(rate.items())\n",
    "X = []\n",
    "Y = []\n",
    "for a,b in sd:\n",
    "    X.append(a/10.0)\n",
    "    Y.append(b)\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Score distribution of imgs by photo.net')\n",
    "plt.plot(X,Y)\n",
    "plt.savefig('ds_all.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download image data\n",
    "To better prepare the datasets used for training and classification, we only collected images from two tails. Specifically, we have ~ 12% negative examples from left side and another ~12% examples from right side. Therefore, we define images with rating score below 4.3 as “negative” image, and images with scores over 6.0 as ”positive” images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# download photos\n",
    "for i in range(len(ids)):\n",
    "    id = ids[i]\n",
    "    score = rates[i]\n",
    "    if (score<6.0 and score>4.3):\n",
    "        continue\n",
    "    url = 'http://gallery.photo.net/photo/'+id+'-md.jpg'\n",
    "    urllib.urlretrieve(url,\"dataset/\"+id+\"_\"+str(score)+\".jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canonicalizing Images and Extract labels from file names\n",
    "\n",
    "We observed different size in different images. Therefore we have cropped images into a square(only keep the center region) and down-sampling them into 96 x 96 pixels image. Also, we parsed the labels from filenames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def crop_and_scale_image(im):\n",
    "    if im.mode is not 'RGB':\n",
    "        im = im.convert('RGB')\n",
    "    width,height = im.size\n",
    "    if width > height:\n",
    "        diff = width - height\n",
    "        box = diff/2, 0, width - (diff - diff/2), height\n",
    "    else:\n",
    "        diff = height - width\n",
    "        box = 0, diff/2, width, height - (diff - diff/2)\n",
    "    im = im.crop(box)\n",
    "    toSize = 96,96\n",
    "    im= im.resize(toSize, Image.ANTIALIAS)\n",
    "    return im\n",
    "\n",
    "def fnames_to_labels(fnames):\n",
    "    res = []\n",
    "    for fname in fnames:\n",
    "        score = float(fname.split('_')[1].split('.jpeg')[0])\n",
    "        if score > 5:\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(-1)\n",
    "    return np.asarray(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Validate / Test splits\n",
    "\n",
    "Next we have loaded all the 9047 images (4503 pos and 4544 neg) and perform our usual data split. We splited these photos into three categories - 7547 for training, 1000 for validation, and and 500 for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4503 4544\n",
      "Train data size:  7547\n",
      "Validation data size:  1000\n",
      "Test data size:  500\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "dname = \"dataset/\"\n",
    "im_paths = [dname+fname for fname in os.listdir(dname) if fname.endswith(\".jpeg\")]\n",
    "im_paths = np.array(im_paths)\n",
    "random.shuffle(im_paths)\n",
    "im_labels = fnames_to_labels(im_paths)\n",
    "\n",
    "im_paths_pos = im_paths[im_labels>0]\n",
    "im_paths_neg = im_paths[im_labels<0]\n",
    "print len(im_paths_pos),len(im_paths_neg)\n",
    "fnames_te = np.concatenate((im_paths_pos[0:250], im_paths_neg[:250]))\n",
    "fnames_va = np.concatenate((im_paths_pos[250:750], im_paths_neg[250:750]))\n",
    "fnames_tr = np.concatenate((im_paths_pos[750:len(im_paths_neg)], im_paths_neg[750:]))\n",
    "print \"Train data size: \",len(fnames_tr)\n",
    "print \"Validation data size: \",len(fnames_va)\n",
    "print \"Test data size: \",len(fnames_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color histogram\n",
    "\n",
    "Now we start to extract image features. As aesthetic value is affected by color of image. Color distribution can be represented and visualized using color histogram. Thus, in the first approach, we will explore to use color histogram as features for SVM classifier. The below figure shows the color histogram of an example image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEACAYAAABRQBpkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1278d8110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_color_histogram(fname):\n",
    "    ans = []\n",
    "    img = cv2.imread(fname)\n",
    "    for channel in range(3):\n",
    "        try:\n",
    "            hist = cv2.calcHist([img],[channel],None,[256],[0,256])\n",
    "            ans.extend([i[0] for i in hist])\n",
    "        except:\n",
    "            ans.extend([0 for i in range(256)])\n",
    "#         plt.plot(hist)\n",
    "#     plt.show()\n",
    "    return ans\n",
    "\n",
    "hist = get_color_histogram('dataset/2572191_6.33.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier\n",
    "\n",
    "After extracting features from color histogram, We applied support vector machine(SVM) to train the classifier. The SVM is known for maximizing margin and can be worked with various kernel, therefore be selected for our binary classification algorithm. We obtained the image pixels and labels from crawled dataset and normalized the color histogram features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tr = [get_color_histogram(fname) for fname in fnames_tr]\n",
    "X_va = [get_color_histogram(fname) for fname in fnames_va]\n",
    "X_te = [get_color_histogram(fname) for fname in fnames_te]\n",
    "y_tr = fnames_to_labels(fnames_tr) \n",
    "y_va = fnames_to_labels(fnames_va) \n",
    "y_te = fnames_to_labels(fnames_te) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(X,maxX,minX):\n",
    "    X2 = []\n",
    "    for i in range(len(X)):\n",
    "        line = []\n",
    "        for j in range(len(X[i])):\n",
    "            k = (X[i][j]-minX[j])/(maxX[j]-minX[j])\n",
    "            line.append(k)\n",
    "        X2.append(line)\n",
    "    return np.asarray(X2)\n",
    "maxX = np.max(X_tr, 0)\n",
    "minX = np.min(X_tr, 0)\n",
    "X_tr_norm = normalize(X_tr,maxX,minX)\n",
    "X_va_norm = normalize(X_va,maxX,minX)\n",
    "X_te_norm = normalize(X_te,maxX,minX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used grid search to find the best SVM parameters in validation dataset, and then use test data with optimzied parameters to get final classifacation accuracy. We also calculated the recalls (*True positive and True negative rates*). True positive is the fraction of the postive examples which are classifed as positive over all positive examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def svm_train(X, y, C, gamma):\n",
    "    rbf_svc = svm.SVC(kernel='rbf', gamma=gamma, C=C).fit(X, y)\n",
    "    return rbf_svc\n",
    "    pass\n",
    "\n",
    "def svm_predict(svc, X):\n",
    "    return svc.predict(X)\n",
    "\n",
    "C_range = np.logspace(-2, 7, 10)\n",
    "gamma_range = np.logspace(-8, 1, 10)\n",
    "\n",
    "best = 0\n",
    "best_C = 0\n",
    "best_gamma = 0\n",
    "\n",
    "# validation\n",
    "for C in C_range:\n",
    "    for gamma in gamma_range:\n",
    "        svc = svm_train(X_tr_norm, y_tr, C, gamma)\n",
    "        y_p = svm_predict(svc, X_va_norm)\n",
    "        accuracy = np.mean(y_p==y_va)\n",
    "        if accuracy > best:\n",
    "            best = accuracy\n",
    "            best_C = C\n",
    "            best_gamma = gamma\n",
    "        recallT = 0.0\n",
    "        recallF = 0.0\n",
    "        for i in range(len(y_va)):\n",
    "            if (y_p[i]==y_va[i] and y_p[i]>0):\n",
    "                recallT += 1\n",
    "            if (y_p[i]==y_va[i] and y_p[i]<0):\n",
    "                recallF += 1\n",
    "        print \"Validation C: {} gamma:{} accuracy : {} Recall: {},{}\".format( C,gamma,accuracy,recallT/(y_va>0).sum(),recallF/(y_va<=0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performed validations, we find the best parameters are: C = 0.1 and gama = 0.01, which are used for final training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.654\n",
      "Recall:  0.672 0.636\n"
     ]
    }
   ],
   "source": [
    "#  test\n",
    "C = 0.1\n",
    "gamma = 0.01\n",
    "svc = svm_train(X_tr_norm, y_tr, C, gamma)\n",
    "y_pt = svm_predict(svc, X_te_norm)\n",
    "print \"Test accuracy: {}\".format(np.mean(y_pt==y_te))\n",
    "recallT = 0.0\n",
    "recallF = 0.0\n",
    "for i in range(len(y_te)):\n",
    "    if (y_pt[i]==y_te[i] and y_pt[i]>0):\n",
    "        recallT += 1\n",
    "    if (y_pt[i]==y_te[i] and y_pt[i]<0):\n",
    "        recallF += 1\n",
    "print 'Recall: ',recallT/(y_te>0).sum(),recallF/(y_te<=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color histogram result analysis\n",
    "\n",
    "We obtained about 65.4% test accuracy with SVM and RBF kernel. The classification result is not good enough. For aesthetic evaluation, the feature is too abstract and selection is very hard to obtain through traditional computer vision techniques. \n",
    "\n",
    "But this experiment of color histogram gives us insights that it's possible to find a way to extract image features to represent the image aesthetic values. We would need to try more intelligent models to address this problem. In recent researches, convolutional neural network (CNN) performs very well in image tasks because of its deep network and learn capacity. In the next part, we will try to apply CNN to approach this challenging topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with Triplet loss function\n",
    "\n",
    "Inspired from <a href = 'https://devblogs.nvidia.com/parallelforall/understanding-aesthetics-deep-learning/'>Understanding Aesthetics with Deep Learning</a>, a journal form NVIDIA, the challenging problem can be approached by training the Convolution Neural Network of the defined the triplet loss:\n",
    "\n",
    "Triplet loss =  $max(0, c + Dist( \\phi(I_1), \\phi(I_2)) - Dist(\\phi(I_1), \\phi(I_3) )$\n",
    "\n",
    "The objective of this loss function is let CNN learn the similarity between high-quality images, and learn the difference between high-quality and mediocre images. Therefore, by training the network, we hope to learn a feature representation $\\phi(.)$ that the feature distance between two high-quality images is smaller than the feature distance between one high-quality image and one low-quality image. Also, by introducing the margin $c$, we can train the network such that the distance between $\\phi(I_1)$ and $\\phi(I_3)$ is greater by c than the distance between $\\phi(I_1)$ and $\\phi(I_2)$.\n",
    "\n",
    "It is noticeable we are not going to learn the classifier by the triplet loss function and deep network, we are learning features representation method $\\phi(.)$. Once we learned $\\phi(.)$, we will use SVM to train the classifier using the feature representation of images.\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/flm2ng5hvfykek5/triLoss.jpg?raw=1\", height = 800, width = 600>\n",
    "\n",
    "\n",
    "### Data Processing\n",
    "The image dataset, we have split them into 5652 images in training dataset, 1000 images in validation dataset, and 500 images in test dataset. The training dataset have around 2:1 regarding positive images and negative images and validation/test have 1:1 positive images and negative images. \n",
    "\n",
    "### Design Architecture\n",
    "We have chosen using tensorflow to implement the Convolutional Neural Network and train feature representation method $\\phi(.)$. The CNN Net architecture was reference and simplified from the reference paper[1], page 3273. Specifically, we have implemented the network with following parameters.\n",
    "<img src=\"https://www.dropbox.com/s/2h2n33eigsqhsh1/parameterCNN.jpg?raw=1\", height = 300, width = 300>\n",
    "\n",
    "The output of this network is a feature vector with dimension 1024 x 1. The vector is used to calculate the triplet loss and used in Gradient Descent. Also, after the network got trained, this layer is the feature representation of the original image.\n",
    "\n",
    "For training classifier, we have used SVM classifier from sklearn.\n",
    "\n",
    "### Implementation with tensorflow\n",
    "\n",
    "S1: import necessary packages, specify the dataset location and destination file for logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np      \n",
    "from PIL import Image   \n",
    "import random           \n",
    "import time             \n",
    "from sklearn import svm \n",
    "import logging          \n",
    "\n",
    "dataset = './dataset4'\n",
    "logging.basicConfig(filename='cnnlog017.log',level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S2: read all image infomation from the csv file, and divide images into positive images and negative images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Positive Images:  3753\n",
      "Train Set Negative Images:  1899\n",
      "Validation Set Positive Images:  500\n",
      "Validation Set Negative Images:  500\n",
      "Test Set Positive Images:  250\n",
      "Test Set Negative Images:  250\n"
     ]
    }
   ],
   "source": [
    "# Reading train set                                             \n",
    "posImg_ids_Tr = []                                              \n",
    "posImg_scores_Tr = []                                           \n",
    "negImg_ids_Tr = []                                              \n",
    "negImg_scores_Tr = []                                           \n",
    "with open( dataset + '/ratingsInfo/train.csv', 'r') as f:       \n",
    "    f.readline()                                                \n",
    "    for line in f.readlines():                                  \n",
    "        img_id,img_score,img_label = line.strip().split(',')    \n",
    "        if float(img_label) > 0:                                \n",
    "            posImg_ids_Tr.append(img_id)                        \n",
    "            posImg_scores_Tr.append(img_score)                  \n",
    "        else:                                                   \n",
    "            negImg_ids_Tr.append(img_id)                        \n",
    "            negImg_scores_Tr.append(img_score)                  \n",
    "print \"Train Set Positive Images: \", len(posImg_ids_Tr)\n",
    "print \"Train Set Negative Images: \",len(negImg_ids_Tr)                                                   \n",
    "# Reading validation set                                        \n",
    "posImg_ids_Va = []                                              \n",
    "posImg_scores_Va = []                                           \n",
    "negImg_ids_Va = []                                              \n",
    "negImg_scores_Va = []                                           \n",
    "with open(dataset + '/ratingsInfo/validation.csv', 'r') as f:   \n",
    "    f.readline()                                                \n",
    "    for line in f.readlines():                                  \n",
    "        img_id,img_score,img_label = line.strip().split(',')    \n",
    "        if float(img_label) > 0:                                \n",
    "            posImg_ids_Va.append(img_id)                        \n",
    "            posImg_scores_Va.append(img_score)                  \n",
    "        else:                                                   \n",
    "            negImg_ids_Va.append(img_id)                        \n",
    "            negImg_scores_Va.append(img_score)                  \n",
    "            \n",
    "print \"Validation Set Positive Images: \",len(posImg_ids_Va)\n",
    "print \"Validation Set Negative Images: \", len(negImg_ids_Va)\n",
    "\n",
    "# Reading the test set                                          \n",
    "posImg_ids_Te = []                                              \n",
    "negImg_ids_Te = []                                              \n",
    "posImg_scores_Te = []                                           \n",
    "negImg_scores_Te = []                                           \n",
    "with open(dataset + '/ratingsInfo/test.csv', 'r') as f:         \n",
    "    f.readline()                                                \n",
    "    for line in f.readlines():                                  \n",
    "        img_id,img_score,img_label = line.strip().split(',')    \n",
    "        if float(img_label) > 0:                                \n",
    "            posImg_ids_Te.append(img_id)                        \n",
    "            posImg_scores_Te.append(img_score)                  \n",
    "        else:                                                   \n",
    "            negImg_ids_Te.append(img_id)                        \n",
    "            negImg_scores_Te.append(img_score)    \n",
    "\n",
    "print \"Test Set Positive Images: \", len(posImg_ids_Te)\n",
    "print \"Test Set Negative Images: \", len(negImg_ids_Te)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3: Read and store positive images, negative images separately into np.arrays. Note Anchor images are also from positive images dataset. You can think Anchor images as $I_1$ images above. There are more positive examples because half of them are functioned as anchor images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor (Positive) Training Images size  (3753, 96, 96, 3)\n",
      "Positive Training Images size  (3753, 96, 96, 3)\n",
      "Negative Training Images size  (1899, 96, 96, 3)\n",
      "Positive Validation Images size  (500, 96, 96, 3)\n",
      "Negative Training Images size  (500, 96, 96, 3)\n",
      "Positive Test Images size  (250, 96, 96, 3)\n",
      "Negative Test Images size  (250, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "def readImgs_intoNpArray(path, image_id_list, image_score_list):\n",
    "    filenames = []\n",
    "    for img_id, img_score in zip(image_id_list, image_score_list):\n",
    "        name = path + img_id + '_' + img_score + '.jpeg'\n",
    "        filenames.append(name)\n",
    "    imgs = np.array([np.array(Image.open(fname)) for fname in filenames])\n",
    "    return imgs\n",
    "\n",
    "\n",
    "path_Tr = dataset + '/train/'                                              \n",
    "pos_img_Tr = readImgs_intoNpArray(path_Tr, posImg_ids_Tr, posImg_scores_Tr)\n",
    "neg_img_Tr = readImgs_intoNpArray(path_Tr, negImg_ids_Tr, negImg_scores_Tr)\n",
    "anchor_img_Tr = readImgs_intoNpArray(path_Tr, posImg_ids_Tr, posImg_scores_Tr)\n",
    "pos_list_Tr = range(len(pos_img_Tr))                                       \n",
    "neg_list_Tr = range(len(neg_img_Tr))                                       \n",
    "                                                                           \n",
    "path_Va = dataset + '/validation/'                                         \n",
    "pos_img_Va = readImgs_intoNpArray(path_Va, posImg_ids_Va, posImg_scores_Va)\n",
    "neg_img_Va = readImgs_intoNpArray(path_Va, negImg_ids_Va, negImg_scores_Va)\n",
    "                                                                           \n",
    "path_Te = dataset + '/test/'                                               \n",
    "pos_img_Te = readImgs_intoNpArray(path_Te, posImg_ids_Te, posImg_scores_Te)\n",
    "neg_img_Te = readImgs_intoNpArray(path_Te, negImg_ids_Te, negImg_scores_Te)\n",
    "\n",
    "print \"Anchor (Positive) Training Images size \", anchor_img_Tr.shape\n",
    "print \"Positive Training Images size \", pos_img_Tr.shape\n",
    "print \"Negative Training Images size \", neg_img_Tr.shape\n",
    "\n",
    "print \"Positive Validation Images size \", pos_img_Va.shape\n",
    "print \"Negative Training Images size \", neg_img_Va.shape\n",
    "\n",
    "print \"Positive Test Images size \", pos_img_Te.shape\n",
    "print \"Negative Test Images size \", neg_img_Te.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "S4: Implement the Convolutional Neural Network with TensorFlow and train classifier using SVM.\n",
    "\n",
    "\n",
    "There are lots of implementation details and some most important of them are:\n",
    "\n",
    "- For symmetry breaking, kernel weights are initialized with a small amount of noise.\n",
    "- when training SVM classifier, we use a linear kernel with optimized regularization parameter from stochastic validation.\n",
    "- The training set is used to train both CNN for feature representations and used to train the SVM classifier.  However, when training SVM, we used only half positive examples so that training set has the same amount of examples in both classes.\n",
    "- The batched Adam Stochastic Optimization was used to iteratively reduce the loss function. The batch size is selected from our stochastic validation (you will see soon).\n",
    "- For better train the loss function, we observed that learning rate in Adam Stochastic Optimization should decay as the iteration increases. we select the decay parameters to make learning rate following this trend.\n",
    "<img src=\"https://www.dropbox.com/s/p9l0b4s03r6a4x3/learnrate.jpg?raw=1\", height = 300, width = 300>\n",
    "- The results **are not** printed into stdout. All the important results are saved in *.log file in current directory.\n",
    "- You will note the same network was going through three times in each iteration (the first for loop in RunAndTest function). This is because of the batched anchor images, batched positive images, and batched negative images need to go through the network and get their outputs respectively. The triplet loss is calculated after all of them are obtained.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):                                       \n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)                \n",
    "  return tf.Variable(initial)                                     \n",
    "                                                                  \n",
    "def bias_variable(shape):                                         \n",
    "  initial = tf.constant(0.1, shape=shape)                         \n",
    "  return tf.Variable(initial)                                     \n",
    "                                                                  \n",
    "def max_pool_2x2(x):                                              \n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],                    \n",
    "                        strides=[1, 2, 2, 1], padding='SAME')     \n",
    "def avg_pool_2x2(x):                                              \n",
    "  return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1],                    \n",
    "                        strides=[1, 2, 2, 1], padding='SAME')  \n",
    "\n",
    "def predict_from_features(X_train, y, X_test, SVMReg = 1):                                              \n",
    "                                                                                                        \n",
    "    # C = 1 # SVM regularization parameter                                                              \n",
    "                                                                                                        \n",
    "    lin_svc = svm.SVC(kernel='linear', C=SVMReg, verbose=True, max_iter= 1000000).fit(X_train, y)       \n",
    "                                                                                                        \n",
    "    Te_res = lin_svc.predict(X_test)                                                                    \n",
    "    Tr_res = lin_svc.predict(X_train)                                                                   \n",
    "    return Te_res, Tr_res                                                                               \n",
    "                                                                                                        \n",
    "# featuresRes1: features positive                                                                       \n",
    "# featuresRes2: features negative                                                                       \n",
    "def doSVM(featuresRes_pos_Tr,featuresRes_neg_Tr, featuresRes_pos_Te, featuresRes_neg_Te, SVMReg = 1):   \n",
    "    TrainExamplesNum = len(featuresRes_pos_Tr) / 2;                                                     \n",
    "    posTrainX =featuresRes_pos_Tr[:TrainExamplesNum,:]                                                  \n",
    "    posTrainy = np.ones( len(posTrainX) )                                                               \n",
    "                                                                                                        \n",
    "    posTestX =featuresRes_pos_Te                                                                        \n",
    "    posTesty = np.ones( len(posTestX) )                                                                 \n",
    "                                                                                                                                                                       \n",
    "    negTrainX = featuresRes_neg_Tr                                                                      \n",
    "    negTrainy = -1 * np.ones( len(negTrainX) )                                                          \n",
    "    negTestX = featuresRes_neg_Te                                                                       \n",
    "    negTesty = -1 * np.ones( len(negTestX) )                                                            \n",
    "                                                                                                        \n",
    "    trainX =  np.concatenate((posTrainX, negTrainX), axis=0)                                            \n",
    "    trainX = trainX.astype(float)                                                                       \n",
    "    trainy =  np.concatenate((posTrainy, negTrainy))                                                    \n",
    "                                                                                                        \n",
    "    testX =  np.concatenate((posTestX, negTestX), axis=0)                                               \n",
    "    testX = testX.astype(float)                                                                         \n",
    "    testy =  np.concatenate((posTesty, negTesty))                                                       \n",
    "                                                                                                        \n",
    "    start = time.time()                                                                                 \n",
    "    y_p, y_p_tr = predict_from_features(trainX, trainy, testX, SVMReg)                                  \n",
    "    # np.savetxt(\"predict.csv\", y_p, delimiter=',')                                                     \n",
    "    # y_p_tr = predict_from_features(trainX, trainy, testX, max_iter)                                   \n",
    "    end = time.time()                                                                                   \n",
    "    recallT = 0.0                                                                                       \n",
    "    recallF = 0.0                                                                                       \n",
    "    try:                                                                                                \n",
    "        for i in range(len(testy)):                                                                     \n",
    "            if (y_p[i] == testy[i] and y_p[i]>0):                                                       \n",
    "                recallT += 1                                                                            \n",
    "            if (y_p[i] == testy[i] and y_p[i]<0):                                                       \n",
    "                recallF += 1                                                                            \n",
    "        recall = [recallT/(testy>0).sum(),recallF/(testy<0).sum()]                                      \n",
    "    except:                                                                                             \n",
    "        recall = []                                                                                     \n",
    "                                                                                                        \n",
    "    train_acc = np.mean(y_p_tr == trainy)                                                                                                                                                                    \n",
    "    return np.mean(y_p == testy), end-start, recall, y_p, train_acc                                     \n",
    "\n",
    "def RunAndTest( pos_img, neg_img, anchor_img, pos_list, neg_list, pos_img_Te, ne_img_Te, pos_img_Va, neg_img_Va, margin=1000, keepProb = 0.2, learningRate=1e-4, iter_time=200, batch_size = 16, SVMReg = 1):\n",
    "                                                                                                                                                                                                             \n",
    "    sess = tf.InteractiveSession()                                                                                                                                                                           \n",
    "    width = 96                                                                                                                                                                                               \n",
    "    height = 96                                                                                                                                                                                              \n",
    "    channel = 3                                                                                                                                                                                              \n",
    "                                                                                                                                                                                                             \n",
    "    anchor_input = tf.placeholder(tf.float32, [None, width, height, channel])                                                                                                                                \n",
    "    positive_input = tf.placeholder(tf.float32, [None, width, height, channel])                                                                                                                              \n",
    "    negative_input = tf.placeholder(tf.float32, [None, width, height, channel])                                                                                                                              \n",
    "    global_step = tf.Variable(0, trainable=False)                                                                                                                                                            \n",
    "                                                                                                                                                                                                             \n",
    "                                                                                                                                                                                                             \n",
    "    # Initialize variables                                                                                                                                                                                   \n",
    "    W_conv1 = weight_variable([5, 5, 3, 32])                                                                                                                                                                 \n",
    "    b_conv1 = bias_variable([32])                                                                                                                                                                            \n",
    "                                                                                                                                                                                                             \n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])                                                                                                                                                                \n",
    "    b_conv2 = weight_variable([64])                                                                                                                                                                          \n",
    "                                                                                                                                                                                                             \n",
    "    W_conv3 = weight_variable([3, 3, 64, 128])                                                                                                                                                               \n",
    "    b_conv3 = weight_variable([128])                                                                                                                                                                         \n",
    "                                                                                                                                                                                                             \n",
    "    W_conv4 = weight_variable([3, 3, 128, 256])                                                                                                                                                              \n",
    "    b_conv4 = weight_variable([256])                                                                                                                                                                         \n",
    "                                                                                                                                                                                                             \n",
    "    W_conv5 = weight_variable([3, 3, 256, 256])                                                                                                                                                              \n",
    "    b_conv5 = weight_variable([256])                                                                                                                                                                         \n",
    "                                                                                                                                                                                                             \n",
    "    W_fcl = weight_variable([3 * 3 * 256, 1024])                                                                                                                                                             \n",
    "    b_fcl = weight_variable([1024])                                                                                                                                                                          \n",
    "    fcl = []                                                                                                                                                                                                 \n",
    "    flat_list = []                                                                                                                                                                                           \n",
    "    for train_img in [anchor_input, positive_input, negative_input]:                                                                                                                                         \n",
    "        # CNN1                                                                                                                                                                                               \n",
    "        h_conv1 = tf.nn.relu(tf.nn.conv2d(train_img, W_conv1, [1,1,1,1], 'SAME') + b_conv1)                                                                                                                  \n",
    "        h_pool1 = max_pool_2x2(h_conv1)                                                                                                                                                                      \n",
    "                                                                                                                                                                                                             \n",
    "        # CNN2                                                                                                                                                                                               \n",
    "        h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, [1,1,1,1], 'SAME') + b_conv2)                                                                                                                    \n",
    "        h_pool2 = max_pool_2x2(h_conv2)                                                                                                                                                                      \n",
    "                                                                                                                                                                                                             \n",
    "        # CNN3                                                                                                                                                                                               \n",
    "        h_conv3 = tf.nn.relu(tf.nn.conv2d(h_pool2, W_conv3, [1,1,1,1], 'SAME') + b_conv3)                                                                                                                    \n",
    "        h_pool3 = max_pool_2x2(h_conv3)                                                                                                                                                                      \n",
    "                                                                                                                                                                                                             \n",
    "        # CNN4                                                                                                                                                                                               \n",
    "        h_conv4 = tf.nn.relu(tf.nn.conv2d(h_pool3, W_conv4, [1,1,1,1], 'SAME') + b_conv4)                                                                                                                    \n",
    "        h_pool4 = max_pool_2x2(h_conv4)                                                                                                                                                                      \n",
    "                                                                                                                                                                                                             \n",
    "        # CNN5                                                                                                                                                                                               \n",
    "        h_conv5 = tf.nn.relu(tf.nn.conv2d(h_pool4, W_conv5, [1,1,1,1], 'SAME') + b_conv5)                                                                                                                    \n",
    "        h_pool5 = avg_pool_2x2(h_conv5)                                                                                                                                                                      \n",
    "                                                                                                                                                                                                             \n",
    "        # flatten the CNN                                                                                                                                                                                    \n",
    "        h_pool5_flat = tf.reshape(h_pool5, [-1, 3 * 3 * 256])                                                                                                                                                \n",
    "                                                                                                                                                                                                             \n",
    "        h_fcl = tf.nn.relu(tf.matmul(h_pool5_flat, W_fcl) + b_fcl)                                                                                                                                           \n",
    "        h_fcl = tf.nn.dropout(h_fcl, keep_prob=keepProb)                                                                                                                                                     \n",
    "                                                                                                                                                                                                             \n",
    "        fcl.append(h_fcl)                                                                                                                                                                                    \n",
    "        flat_list.append(h_pool5_flat)                                                                                                                                                                       \n",
    "                                                                                                                                                                                                             \n",
    "    anchor_image = fcl[0]                                                                                                                                                                                    \n",
    "    positive_image = fcl[1]                                                                                                                                                                                  \n",
    "    negative_image = fcl[2]                                                                                                                                                                                  \n",
    "    d_pos = tf.reduce_sum(tf.square(anchor_image - positive_image), 1)                                                                                                                                       \n",
    "    d_neg = tf.reduce_sum(tf.square(anchor_image - negative_image), 1)                                                                                                                                       \n",
    "                                                                                                                                                                                                             \n",
    "    triplet_loss_val = tf.maximum(0., margin + d_pos - d_neg)                                                                                                                                                \n",
    "    triplet_loss = tf.reduce_mean(triplet_loss_val)                                                                                                                                                          \n",
    "                                                                                                                                                                                                             \n",
    "    decay_lr = tf.train.exponential_decay(learningRate, global_step, 100, 0.975, staircase=True)                                                                                                             \n",
    "    train_step = tf.train.AdamOptimizer(decay_lr).minimize(triplet_loss, global_step=global_step)                                                                                                            \n",
    "                                                                                                                                                                                                             \n",
    "    sess.run(tf.global_variables_initializer())                                                                                                                                                              \n",
    "    print \"start AdamOptimizer...\"                                                                                                                                                                                     \n",
    "                                                                                                                                                                                                             \n",
    "    # Iteration begins                                                                                                                                                                                       \n",
    "    for i in range(iter_time):                                                                                                                                                                               \n",
    "        # Select train batch                                                                                                                                                                                 \n",
    "        batch_anchor = anchor_img[random.sample(pos_list, batch_size)]                                                                                                                                       \n",
    "        batch_pos = pos_img[random.sample(pos_list, batch_size)]                                                                                                                                             \n",
    "        batch_neg = neg_img[random.sample(neg_list, batch_size)]                                                                                                                                             \n",
    "                                                                                                                                                                                                             \n",
    "        # Train a step                                                                                                                                                                                       \n",
    "        train_step.run(feed_dict={anchor_input: batch_anchor, positive_input: batch_pos, negative_input: batch_neg})                                                                                         \n",
    "                                                                                                                                                                                                             \n",
    "        lossVal = triplet_loss.eval( feed_dict={anchor_input: batch_anchor, positive_input: batch_pos, negative_input: batch_neg} )                                                                          \n",
    "        print \"lossVal: \", lossVal                                                                                                                                                                           \n",
    "                                                                                                                                                                                                             \n",
    "        if i is not 1 and i % 5000 is 1:                                                                                                                                                                     \n",
    "            print \"iteration at: \" + str(i)                                                                                                                                                                  \n",
    "            print \"Start Evaluate the feature...\"                                                                                                                                                            \n",
    "                                                                                                                                                                                                             \n",
    "            # Train data features                                                                                                                                                                            \n",
    "            # positive Train Features                                                                                                                                                                        \n",
    "            featuresRes_pos_Tr = fcl[1].eval( feed_dict={anchor_input: pos_img, positive_input: pos_img, negative_input: neg_img })                                                                          \n",
    "            # negative Train Features                                                                                                                                                                        \n",
    "            featuresRes_neg_Tr = fcl[2].eval( feed_dict={anchor_input: pos_img, positive_input: pos_img, negative_input: neg_img})                                                                           \n",
    "                                                                                                                                                                                                             \n",
    "            # positive validation features                                                                                                                                                                   \n",
    "            featuresRes_pos_Va = fcl[1].eval( feed_dict={anchor_input: pos_img_Va, positive_input: pos_img_Va, negative_input: neg_img_Va} )                                                                 \n",
    "            # negative validation features                                                                                                                                                                   \n",
    "            featuresRes_neg_Va = fcl[2].eval( feed_dict={anchor_input: pos_img_Va, positive_input: pos_img_Va, negative_input: neg_img_Va})                                                                  \n",
    "                                                                                                                                                                                                             \n",
    "            print \"start SVM...\"                                                                                                                                                                             \n",
    "            Testacc, SVMtime, Recall, y_p, train_acc = doSVM(featuresRes_pos_Tr, featuresRes_neg_Tr, featuresRes_pos_Va, featuresRes_neg_Va, SVMReg)                                                         \n",
    "            logging.info(\"At iteration: \" + str(i) + \" loss value: \" + str(lossVal) + \" recall: \" + str(Recall) + \" Train Accuracy: \" + str(train_acc) + \", Test Accuracy: \" + str(Testacc) )                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skeleton code was referred from an MNIST digit classification example from tensorflow website: https://www.tensorflow.org/versions/r0.10/tutorials/mnist/pros/index.html. \n",
    "\n",
    "#### Run the stochastic validation to select good hyperparameters and test the algorithm.\n",
    "\n",
    "One of greatest challenges in deep networks are always selecting parameters. We did not use grid search to find the best parameters since there are too many parameters to tune (in our case, there are 5 parameters and 576 combinations), and each of them takes hours to train. Alternatively, We used the stochastic method to tune the parameters and record the parameters and results in the .log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "margins  = [1, 10, 100, 1000]\n",
    "batchSizes = [16 ,32, 64]\n",
    "dropOutProbs = [0.01, 0.2, 0.3, 0.5]\n",
    "learnRates = [5e-4, 2e-4, 1e-4, 5e-5]\n",
    "SVMRegularizations = [0.1,1,10]\n",
    "iterationTime = 10001\n",
    "for i in range(100):\n",
    "    margin = random.choice(margins)\n",
    "    batch_size = random.choice(batchSizes)\n",
    "    dropOutProb = random.choice(dropOutProbs)\n",
    "    learnRate = random.choice(learnRates)\n",
    "    SVMreg = random.choice(SVMRegularizations)\n",
    "    logging.info( \"time: \" + str(i) + \"margin: \" + str(margin) + \" batchSize: \" + str(batch_size) + \" dropOut: \" + str(dropOutProb) + \" learnRate: \" + str(learnRate) + \" SVM REG: \"  + str(SVMreg) )\n",
    "    testErr = RunAndTest(pos_img_Tr, neg_img_Tr, anchor_img_Tr, pos_list_Tr, neg_list_Tr, pos_img_Te, neg_img_Te, pos_img_Va, neg_img_Va, margin=margin, keepProb=dropOutProb, learningRate=learnRate, iter_time= iterationTime, batch_size = batch_size, SVMReg = SVMreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our stochastic validation, we repeatedly to randomly select one parameter combination from hyperplane and record the parameters resulting in best validation accuracy. We have opened 1 x c4.8xlarge instance (36 cores) and 3 x c4.4xlarge (16 cores) in AWS and test 100 parameter combinations in total, this takes about 18 hours to finish. We found that the best parameters are:\n",
    "\n",
    "margin: 10 , batchSize: 16, dropOut: 0.2, learnRate: 5e-05, SVM REG: 0.1\n",
    "\n",
    "We used the selected parameters on the test dataset and achieved 66.8% test accuracy, with True positive 69.6% and True negative 64%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN with Triplet loss function result analysis\n",
    "\n",
    "The result from CNN network can achieve 66.8% accuracy, it demonstrates the effectiveness of the feature selection by using triplet loss to train the convolutional network, but it is still not as good as expected, through we have paid lots of efforts on tuning the parameters and optimizing the network structure. We have the summaries that the reasons might be:\n",
    "\n",
    "- Structure of network: \n",
    "The convolution network is not deep and wide enough to extract best features. In VGG16, there are 13 convolutional  layers and 3 fully connected layers. Therefore, VGG is able to extract very good features with its strong network and tuned parameters. With the network only have 5 convolutional layers and 1 fully connected layer, the best features are not easily extracted.\n",
    "\n",
    "- Parameters tuning: \n",
    "Selecting the right parameters actually takes lots of more time and resources. We do have the implemented the stochastic validation to find the good parameters, but it is not enough. The choice set of each parameter are come from our experiments and experience, in reality we need to try much more different parameters. Also, we need to do more runs and validations to find the best parametres.\n",
    "\n",
    "- Network Optimization: \n",
    "There are also lots of things to tune in the network. e.g. In convolutional layers, the size of kernel, the pooling methods, the activation function, the number of channels etc. In whole network, the number of convolutional or fully connected layers, the number of neurons in fully connected layers, etc.\n",
    "\n",
    "To achieve the best performance there are lots of work to do, unfortunately, at this time we are not able to do all of them due to time and resources limit. We implemented the simplified network to indicates the effectiveness of this approach, and we do think the capability of this approaches once it got well trained and tuned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Feature Extraction using VGG16 pretrained network\n",
    "\n",
    "The limitation of training the CNN from scratch makes us think of using pre-trained models for some popular pre-defined nets. We choose VGG16 to get the pre-trained model since it has been well defined and trained with very deep network and it generalizes well to other datasets. The VGG pre-trained weights are available at its <a href = \"https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view\">source website</a>. We have used the pre-trained model to extract features for images. Note We use the output from the flatten layer as extracted features for images.\n",
    "\n",
    "The codes are referred from <a href = \"https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\"> VGG16 github page </a> and some changed has been made to fit for our original image size and desired feature output. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "    \n",
    "    new_model = Sequential()\n",
    "    new_model.add(ZeroPadding2D((1,1),input_shape=(3,96,96)))\n",
    "    new_model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    new_model.add(ZeroPadding2D((1,1)))\n",
    "    new_model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    new_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    new_model.add(ZeroPadding2D((1,1)))\n",
    "    new_model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    new_model.add(ZeroPadding2D((1,1)))\n",
    "    new_model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    new_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    new_model.add(ZeroPadding2D((1,1)))\n",
    "    new_model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    new_model.add(ZeroPadding2D((1,1)))\n",
    "    new_model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    new_model.add(ZeroPadding2D((1,1)))\n",
    "    new_model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    new_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    new_model.add(ZeroPadding2D((1,1)))\n",
    "    new_model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    new_model.add(ZeroPadding2D((1,1)))\n",
    "    new_model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    new_model.add(ZeroPadding2D((1,1)))\n",
    "    new_model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    new_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    new_model.add(ZeroPadding2D((1,1)))\n",
    "    new_model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    new_model.add(ZeroPadding2D((1,1)))\n",
    "    new_model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    new_model.add(ZeroPadding2D((1,1)))\n",
    "    new_model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    new_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    new_model.add(Flatten())\n",
    "    \n",
    "    weights = model.get_weights()\n",
    "    new_model.set_weights(weights)\n",
    "    \n",
    "    return new_model\n",
    "    \n",
    "trained_vgg = VGG_16(\"vgg16_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VGG codes are referred from <a href=\"https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\"> VGG Keras Github page </a>. \n",
    "After load the pre-trained weights into VGG16 network, we can now transform original images (3x 96 x 96) into feature vectors (1 x 4608) from flatten layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_Vgg16features(fnames, vgg):\n",
    "    result = []\n",
    "    for fname in fnames:\n",
    "        im = Image.open(fname)\n",
    "        im = crop_and_scale_image(im)\n",
    "        if im.mode is not 'RGB':\n",
    "            im = im.convert('RGB')\n",
    "        npim = np.asarray(im)\n",
    "        vgg_input = np.rollaxis(npim, 2)\n",
    "        result.append(vgg_input)\n",
    "        \n",
    "    result_np = np.asarray(result)\n",
    "    print result_np.shape\n",
    "    return vgg.predict(result_np), fnames_to_labels(fnames)\n",
    "\n",
    "X_tr, y_tr = get_Vgg16features(fnames_tr, trained_vgg)\n",
    "X_va, y_va = get_Vgg16features(fnames_va, trained_vgg)\n",
    "X_te, y_te = get_Vgg16features(fnames_te, trained_vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dimension of vgg features is 4608, which is larger than the size of dataset, it is easy to overfit when we train the models since we only have ~2800 training examples. Therefore, we applied PCA to extract principle components as new features but has lower dimension, and train the SVM classifier with new features.To find the best parameters, we did validations and use the optimized parameters to work on testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "best = 0\n",
    "best_C = 0\n",
    "best_gamma = 0\n",
    "best_pca_n = 0\n",
    "\n",
    "# validation\n",
    "for pca_n in [1024,2048,3072,4096]:\n",
    "    pca = PCA(n_components=pca_n)\n",
    "    X_tr_pca = pca.fit_transform(X_tr)\n",
    "    X_va_pca = pca.transform(X_va)\n",
    "    for C in C_range:\n",
    "        for gamma in gamma_range:\n",
    "            svc = svm_train(X_tr_pca, y_tr, C, gamma)\n",
    "            y_p = svm_predict(svc, X_va_pca)\n",
    "            accuracy = np.mean(y_p==y_va)\n",
    "            if accuracy > best:\n",
    "                best = accuracy\n",
    "                best_C = C\n",
    "                best_gamma = gamma\n",
    "                best_pca_n = pca_n\n",
    "            recallT = 0.0\n",
    "            recallF = 0.0\n",
    "            for i in range(len(y_va)):\n",
    "                if (y_p[i]==y_va[i] and y_p[i]>0):\n",
    "                    recallT += 1\n",
    "                if (y_p[i]==y_va[i] and y_p[i]<0):\n",
    "                    recallF += 1\n",
    "            print \"Validation PCA_N: {} C: {} gamma:{} accuracy: {} Recall: {},{}\".format(pca_n,C,gamma,accuracy,recallT/(y_va>0).sum(),recallF/(y_va<=0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got the optimized parameters: SVM regularization parameter C = 1, RBF kernel radius gamma = 1e-6, and use PCA to extract 3072 principle components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test\n",
    "pca_n = 3072\n",
    "C = 1\n",
    "gamma = 1e-6\n",
    "pca = PCA(n_components=pca_n)\n",
    "X_tr_pca = pca.fit_transform(X_tr)\n",
    "X_te_pca = pca.transform(X_te)\n",
    "svc = svm_train(X_tr_pca, y_tr, C, gamma)\n",
    "y_pt = svm_predict(svc, X_te_pca)\n",
    "print \"Test accuracy: {}\".format(np.mean(y_pt==y_te))\n",
    "recallT = 0.0\n",
    "recallF = 0.0\n",
    "for i in range(len(y_te)):\n",
    "    if (y_pt[i]==y_te[i] and y_pt[i]>0):\n",
    "        recallT += 1\n",
    "    if (y_pt[i]==y_te[i] and y_pt[i]<0):\n",
    "        recallF += 1\n",
    "print 'Recall: ',recallT/(y_te>0).sum(),recallF/(y_te<=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy is: 84% with True positive 83.2% and True negative 84.8%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG newtwork result analysis\n",
    "\n",
    "Since VGG has deep network and generalize well to other datasets[3]. The VGG16 pre-trained model did improve the model accuracy to 84%. Because VGG network is not explicitly learning the aesthetic features, There are still some images are misclassified. An improvement can be done is that use pre-trained weights as initial values and further train the network by optimizing the triplet loss, therefore aesthetic features can be better extracted. Also, the aesthetic classification is not an easy problem. We can see from the False positive and False negative samples that some misclassified images are even hard to be classified correctly by people:\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/pb826ivkhhzunte/false.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this project, we have come up different approaches and implemented all pipelines to answer the very challenge problem: evaluate the aesthetic values for photos. 36,692 original photos with scores were crawled from photo.net and   ~9,000 of them with very high or very low scores were selected to form training, validation and test sets. We experimented with different models to train the machine to be an 'aesthetic evaluator'. As the baseline, color histogram was built to extract features for SVM classifier and achieve 65.4% test accuracy. To improve the accuracy, we used the defined triplet loss to train a simplified Convolutional network and learned the aesthetic features. The accuracy of SVM classifier trained on these features has achieved 66.8% test accuracy, not a significant improvement because resources limitations but has great improvement space. Finally, we have used the pre-trained very deep VGG16 network to obtain features and learned the SVM classifier, the test accuracy of 84% has been achieved.\n",
    "\n",
    "### Limitations and Further Consideration\n",
    "\n",
    "We are addressing a very challenging problem. Accurately evaluate the aesthetic value of an image is very difficult, even with the human. Some photos are too abstract to be recognized and appreciated. Also, the aesthetic value is a bit of subjective, although people has common sense about beauty, but possibilities exist that different people have different perspectives and experiences. Therefore, the goal of this project does not achieve a perfect classifier, but try to give people a rough value of the photos for reference. Also, we would like to try to approach this challenging problem and reinforce our understandings on data processing and deep learning fields. \n",
    "\n",
    "There are lots of improvements can be considered. We have witnessed a very deep network like VGG is powerfully working on images, and the triplet loss function is very good 'learning criteria'. Hence, I believe an algorithm combines them will yield to better accuracy. We can either use pre-train weights as initial variables and further train the VGGNet by triplet loss, or a CNN has a similar structure as VGG16Net can be built and trained from scratch. After appropriate parameter tuning and apply some tricks we think the accuracy could be significantly improved. Also, there is improvement can be done in the dataset. We have only used ~9,000 high contrast images for training the network and this is typically not enough for a deep network. Getting more training images with high contrast will improve the accuracy.\n",
    "\n",
    "### Reference\n",
    "1. Understanding Aesthetics with Deep Learning. NVIDIA Website, Available:  https://devblogs.nvidia.com/parallelforall/understanding-aesthetics-deep-learning/\n",
    "2. Deep MNIST for Experts on tensorflow. Available: https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/index.html\n",
    "3. VGG16 Github Keras. Available: https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "4. Data source we used to crawl: http://photo.net/\n",
    "5. Simultaneous Feature Learning and Hash Coding with Deep Neural Networks, Hanjiang Lai† , Yan Pan, Ye Liu , and Shuicheng Yan, CVPR 2015.\n",
    "6. VGG homepage, Available: http://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "7. Part of work are referred from CMU practical data science homework, Available: http://www.datasciencecourse.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
